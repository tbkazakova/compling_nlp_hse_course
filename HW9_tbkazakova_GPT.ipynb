{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNKpIGwdFJx1",
        "outputId": "2de85c2e-6ee9-4e73-ef80-4cc40f470273",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mPySuJ6eEGhM"
      },
      "outputs": [],
      "source": [
        "from transformers.utils import logging\n",
        "logging.set_verbosity(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nVPq82s-5qE1"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "DEVICE = torch.device(\"cuda:0\")\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å ruGPT –æ—Ç —Å–±–µ—Ä–∞\n",
        "model_name_or_path = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name_or_path, use_cache=False).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7tRau3_E-8o",
        "outputId": "7fc9dbbf-e778-40cd-fc0d-9d177671a944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "–ö–∞–∫ —Ç—ã —ç—Ç–æ –¥–µ–ª–∞–µ—à—å?\n",
            "\n",
            "‚Äî¬†–Ø –Ω–µ –∑–Ω–∞—é,¬†‚Äî –æ—Ç–≤–µ—Ç–∏–ª –æ–Ω.¬†‚Äî\n"
          ]
        }
      ],
      "source": [
        "text = \"–ö–∞–∫ —Ç—ã —ç—Ç–æ –¥–µ–ª–∞–µ—à—å?\" # —Ä–∞–±–æ—Ç–∞–µ—Ç\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "out = model.generate(input_ids, do_sample=False)\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QByyuFm4gy_D"
      },
      "source": [
        "# –î–æ–æ–±—É—á–µ–Ω–∏–µ GPT\n",
        "\n",
        "–ß—Ç–æ–±—ã –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –≤ –Ω—É–∂–Ω–æ–º —Å—Ç–∏–ª–µ/–¥–æ–º–µ–Ω–µ, –º–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∏—Ç—å GPT –Ω–∞ —Å–≤–æ–µ–º –∫–æ—Ä–ø—É—Å–µ. –î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGOrGXd7Pj_z",
        "outputId": "7962f264-df20-445d-c1ff-9d1ab7bc677e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–≠—Ç–æ —Ç–µ–∫—Å—Ç—ã –õ–µ–Ω—ã –ñ–∏–ª–∏–Ω–æ–π (—Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ + –ø–µ—Ä–µ–≤–æ–¥—ã + —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –ë—ë—Ä–Ω—Å–∞ –≤ –ø–µ—Ä–µ–≤–æ–¥–µ –ú–∞—Ä—à–∞–∫–∞)"
      ],
      "metadata": {
        "id": "n7jdFGMyRpsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/–í–®–≠/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/NLP/Lena_texts.txt', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HckdJo08Pee2",
        "outputId": "e1b294d4-2f0c-4d6f-9446-879eb592830e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'–ê —á—Ç–æ? –í—Å–µ–≥–æ –ª–∏—à—å —Ç—Ä–µ—Ç—å–µ–≥–æ –¥–Ω—è\\n–ü–æ–ø—É—Ç—á–∏–∫ —Å–ª–∞–≤–Ω—ã–π –±—ã–ª —É –º–µ–Ω—è.\\n–í —Ç–µ–ª–µ–≥—É —Å–≤–æ—é —É—Å–∞–¥–∏–ª, –≤ –æ–≤—ë—Å\\n–ù–æ –Ω–∏–∫—É–¥–∞ –Ω'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soPxrXgQpFZQ",
        "outputId": "41d87c0e-8ee4-4f59-f110-c866cd84121c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω–∏–º –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ .txt —Ñ–∞–π–ª\n",
        "train_path = 'train_dataset.txt'\n",
        "with open(train_path, \"w\", encoding='utf-8') as f:\n",
        "    f.write(text)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "train_dataset = TextDataset(tokenizer=tokenizer,file_path=train_path,block_size=64,\n",
        "                            overwrite_cache=True)\n",
        "\n",
        "# —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø–æ–¥–∞–≤–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω–æ–º –µ–π –≤–∏–¥–µ\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_8m7ZLOpPCg"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ\n",
        "–ß–µ—Ä–µ–∑ –∫–ª–∞—Å—Å Trainer —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤—Å–µ –æ–±—É—á–µ–Ω–∏–µ, –æ—Å—Ç–∞–Ω–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–∏—Ç (—Ç–æ—á–Ω–µ–µ —Ç—Ä–µ–π–Ω –≤ —Å–ª—É—á–∞–µ hg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "tC39igSfSjfx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT9JbPzvSKmS",
        "outputId": "f79e4d8b-06d7-4365-9d0b-2fbf20af9fbe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.65.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_yeSqEZSvHZ",
        "outputId": "77bf6412-2b66-4941-feee-1c823a674d19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sQH4wBW_pN2d"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"./finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=100,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    gradient_accumulation_steps=16,\n",
        "    )\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None) # Optimizer and lr scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVtvq4sLq9EG",
        "outputId": "128cea9a-5558-4262-eafb-e7f74e22f108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_runtime': 147.5915, 'train_samples_per_second': 59.624, 'train_steps_per_second': 0.678, 'train_loss': 0.41169525146484376, 'epoch': 100.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=0.41169525146484376, metrics={'train_runtime': 147.5915, 'train_samples_per_second': 59.624, 'train_steps_per_second': 0.678, 'train_loss': 0.41169525146484376, 'epoch': 100.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_qjIcBUrq0j",
        "outputId": "59f5a979-3909-4943-a8e9-096b51d7e774",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "–ö–∞–∫ —Ç—ã —ç—Ç–æ –¥–µ–ª–∞–µ—à—å?¬†‚Äî —è –ø–æ—á—Ç–∏ –ø–ª–∞–∫–∞–ª–∞.¬†‚Äî –° —Ç–æ–±–æ–π –≤—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ?\n",
            "\n",
            "‚Äî¬†–ù–µ—Ç. –î–∞, –≤—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ.\n",
            "\n",
            "‚Äî¬†–û, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞!¬†‚Äî —Å–∫–∞–∑–∞–ª–∞ —è.¬†‚Äî –Ø —Ç–∞–∫ –ø–æ —Ç–µ–±–µ —Å–∫—É—á–∞—é! –ú–Ω–µ —Ç–∞–∫ —Ö–æ—á–µ—Ç—Å—è, —á—Ç–æ–±—ã —Ç—ã –ø–æ—Å–∫–æ—Ä–µ–µ –ø—Ä–∏–µ—Ö–∞–ª! –Ø –æ—á–µ–Ω—å —Å–∫—É—á–∞—é‚Ä¶\n",
            "\n",
            "‚Äî¬†–Ø –ø—Ä–∏–µ—Ö–∞–ª, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ç–µ–±—è!\n",
            "\n",
            "‚Äî¬†–ê —Ç—ã –∫–∞–∫?\n",
            "\n",
            "‚Äî¬†–ö–∞–∫?\n",
            "\n",
            "‚Äî¬†–Ø –±—ã —Ç–µ–±—è —Ç–æ–∂–µ —É–≤–∏–¥–µ–ª, –µ—Å–ª–∏ –±—ã —Ç—ã –∫–æ –º–Ω–µ –ø—Ä–∏—à–ª–∞‚Ä¶\n",
            "\n",
            "‚Äî¬†–ò —è –∫ —Ç–µ–±–µ! –ê –≤—ã?\n",
            "\n",
            "‚Äî¬†–Ø –ø—Ä–∏—à–µ–ª –∫ —Ç–µ–±–µ‚Ä¶\n",
            "\n",
            "–û–Ω –ø–æ–º–æ–ª—á–∞–ª.\n",
            "\n",
            "‚Äî¬†–Ø –Ω–µ –∑–Ω–∞—é, —á—Ç–æ –º–Ω–µ –¥–µ–ª–∞—Ç—å, –º–∏–ª–∞—è. –ê —Ç—ã?\n",
            "\n",
            "‚Äî¬†–Ø –Ω–µ –∏—â—É —Ç–µ–±—è,¬†‚Äî —Å–∫–∞–∑–∞–ª–∞ —è.¬†‚Äî –Ø –∏—â—É —Ç–µ–±—è, —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å, –≥–¥–µ —Ç—ã.\n",
            "\n",
            "–û–Ω –ø–æ–∂–∞–ª –ø–ª–µ—á–∞–º–∏.\n",
            "\n",
            "‚Äî¬†–í –ª—é–±–æ–º —Å–ª—É—á–∞–µ, –Ω–µ —Å–µ–π—á–∞—Å.\n",
            "\n",
            "–ò –º—ã –ø–æ–º–æ–ª—á–∞–ª–∏.\n",
            "\n",
            "‚Äî¬†–Ø –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ —Å–∫—É—á–∞—é,¬†‚Äî —Å–∫–∞–∑–∞–ª–∞ —è.¬†‚Äî –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ, –Ω–µ —Å–µ–π—á–∞—Å.\n",
            "\n",
            "‚Äî¬†–ù—É,¬†‚Äî —Å–∫–∞–∑–∞–ª –æ–Ω, –Ω–µ –æ—Ç–≤–æ–¥—è –≥–ª–∞–∑ –æ—Ç –º–µ–Ω—è.¬†‚Äî –ù–∞–¥–µ—é—Å—å, —Ç—ã –Ω–µ –±—É–¥–µ—à—å –ø—Ä–æ—Ç–∏–≤, –µ—Å–ª–∏ —è –ø—Ä–∏—à–ª—é –∑–∞ —Ç–æ–±–æ–π —Å–≤–æ–µ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞? –Ø –ø—Ä–∏—à–ª—é –∑–∞ —Ç–æ–±–æ–π —Å–≤–æ–µ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞, –º–∏–ª–∞—è.\n",
            "\n",
            "–Ø –æ–ø—É—Å—Ç–∏–ª–∞ –≥–ª–∞–∑–∞, —á—Ç–æ–±—ã –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –¥—ã—Ö–∞–Ω–∏–µ.\n",
            "\n",
            "‚Äî¬†–Ø‚Ä¶ —è –Ω–µ –º–æ–≥—É,¬†‚Äî —Å–∫–∞–∑–∞–ª–∞ —è.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"–ö–∞–∫ —Ç—ã —ç—Ç–æ –¥–µ–ª–∞–µ—à—å?\"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids,\n",
        "                        do_sample=True,\n",
        "                        temperature=0.8,\n",
        "                        top_k=50,\n",
        "                        max_length=300,\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–û–≥–æ"
      ],
      "metadata": {
        "id": "kSTjZSt0WjJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"–ü–æ–ª–æ–Ω –≥–æ—Ä–æ–¥ \"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids,\n",
        "                        do_sample=True,\n",
        "                        temperature=0.8,\n",
        "                        top_k=50,\n",
        "                        max_length=300,\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eTjuxLbW2gq",
        "outputId": "1063ed97-11fd-4526-a7c2-13768b91f58d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "–ü–æ–ª–æ–Ω –≥–æ—Ä–æ–¥ \n",
            "–ì–¥–µ –Ω–∞–¥ –ª–∞–≤–∫–æ–π, \n",
            "–°–≤–µ—Ä—Ö—É –¥–æ–Ω–∏–∑—É, \n",
            "–û–Ω –Ω–∞–¥ –ª–∞–≤–∫–æ–π, \n",
            "–°–≤–µ—Ä—Ö—É –¥–æ–Ω–∏–∑—É, \n",
            "–û–Ω –Ω–∞–¥ –ª–∞–≤–∫–æ–π, \n",
            "–°–≤–µ—Ä—Ö—É –¥–æ–Ω–∏–∑—É, \n",
            "–û–Ω –Ω–∞–¥ –ª–∞–≤–∫–æ–π...\n",
            "–Ø –∂–¥—É —Ç–µ–±—è,\n",
            "–ê —Ç—ã –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—à—å...\n",
            "–ê —è –∂–¥—É —Ç–µ–±—è...\n",
            "–¢—ã –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—à—å...\n",
            "–¢—ã –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—à—å...\n",
            "\n",
            "\n",
            "–°–æ–Ω–µ—Ç, —Å –∫–æ—Ç–æ—Ä—ã–º –≤—á–µ—Ä–∞ –º—ã —Ä–∞—Å—Å—Ç–∞–ª–∏—Å—å\n",
            "–ú—á–∏—Ç—Å—è —Å–∫–≤–æ–∑—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ \n",
            "–°—Ä–µ–¥—å –¥–Ω–µ–π, –º–µ–∂ —Ç–µ–º, –∫–∞–∫ —è –∂–∏–≤—É\n",
            "–ü—Ä–æ–π–¥–µ—Ç –≥–æ–¥–∞,\n",
            "–ò –Ω–µ –±—É–¥–µ—Ç –≤ —ç—Ç–æ–º –≥–æ–¥—É\n",
            "–ü–æ–ø–∞–¥–∞–Ω—å—è.\n",
            "–ò –Ω–µ –±—É–¥–µ—Ç –≤ —ç—Ç–æ–º –≥–æ–¥—É\n",
            "–ü–æ–ø–∞–¥–∞–Ω—å—è.\n",
            "–Ø –∂–¥—É —Ç–µ–±—è,\n",
            "–ê —Ç—ã –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—à—å...\n",
            "–¢—ã –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—à—å...\n",
            "–¢—ã –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—à—å...\n",
            "–ë—É–¥—å –∑–¥–æ—Ä–æ–≤, –ª—é–±–∏–º—ã–π,\n",
            "–°—á–∞—Å—Ç–ª–∏–≤–µ—Ü,\n",
            "–°—á–∞—Å—Ç–ª–∏–≤–µ—Ü,\n",
            "–°—á–∞—Å—Ç–ª–∏–≤–µ—Ü,\n",
            "–°—á–∞—Å—Ç–ª–∏–≤–µ—Ü,\n",
            "–°—á–∞—Å—Ç–ª–∏–≤–µ—Ü,\n",
            "–°—á–∞—Å—Ç–ª–∏–≤–µ—Ü...\n",
            "\n",
            "–ù–æ—è–±—Ä—å\n",
            "\n",
            "–°–æ–Ω–µ—Ç, —Å –∫–æ—Ç–æ—Ä—ã–º –≤—á–µ—Ä–∞ –º—ã —Ä–∞—Å—Å—Ç–∞–ª–∏—Å—å\n",
            "–ú—á–∏—Ç—Å—è —Å–∫–≤–æ–∑—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ\n",
            "–ú—á–∏—Ç—Å—è —Å–∫–≤–æ–∑—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ\n",
            "–ú—á–∏—Ç—Å—è —Å–∫–≤–æ–∑—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ\n",
            "–ú—á–∏—Ç—Å—è —Å–∫–≤–æ–∑—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ\n",
            "–ú—á–∏—Ç—Å—è —Å–∫–≤–æ–∑—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ\n",
            "–ú—á–∏—Ç—Å—è —Å–∫–≤–æ–∑—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ\n",
            "–ú—á–∏—Ç—Å—è —Å–∫–≤–æ–∑—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ\n",
            "–ú—á–∏—Ç—Å—è —Å–∫–≤–æ–∑—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ\n",
            "–ò –Ω–µ –±—É–¥–µ—Ç –≤ —ç—Ç–æ–º –≥–æ–¥—É\n",
            "–ü–æ–ø–∞–¥–∞–Ω—å—è.\n",
            "–Ø –∂–¥—É —Ç–µ–±—è, –ª—é–±–∏–º—ã–π,\n",
            "–°—á–∞—Å—Ç–ª–∏–≤–µ—Ü,\n",
            "–°—á–∞—Å—Ç–ª–∏–≤–µ—Ü,\n",
            "–°—á–∞—Å—Ç\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNOPCA0tEGhV"
      },
      "source": [
        "–ù—É–∂–Ω–æ –ø–æ–ø—Ä–æ—Å–∏—Ç—å –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"–ü–æ–ª–æ–Ω –≥–æ—Ä–æ–¥ \"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids,\n",
        "                        do_sample=True,\n",
        "                        num_beams=5, top_k=50,\n",
        "                        max_length=300,\n",
        "                        repetition_penalty=3.5\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GxK0u5PXNlT",
        "outputId": "0ac425fd-8953-4d3c-ab32-8cf3553ac223"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "–ü–æ–ª–æ–Ω –≥–æ—Ä–æ–¥ \n",
            "–°–Ω–µ–≥–æ–º, —Å–Ω–µ–≥–æ–º –∏ –ª—å–¥–æ–º.\n",
            "–õ–µ–¥—è–Ω—ã–º –≤–∏—Ö—Ä–µ–º\n",
            "–û–Ω –∫—Ä—É–∂–∏—Ç –ø–æ –≥–æ—Ä–æ–¥—É,\n",
            "–ü—Ä—ã–≥–∞–µ—Ç —Å –∫—Ä—ã—à–∏ –Ω–∞ –∫—Ä—ã—à—É,\n",
            "–ê –ø–æ—Ç–æ–º –≤ —Å—É–≥—Ä–æ–±–µ –≤–∞–ª–∏—Ç—Å—è.\n",
            "–ó–µ–ª—ë–Ω—ã–π —à–∞—Ä—Ñ –µ–≥–æ –∫–æ–ª—ã—à–µ—Ç,\n",
            "–ò –æ–Ω –ø–∞–¥–∞–µ—Ç –∑–∞–º–µ—Ä—Ç–≤–æ.\n",
            "–ù–æ –Ω–µ —Ç—É—Ç-—Ç–æ –±—ã–ª–æ!\n",
            "–ö–∞–∫ –Ω–∏ —Å—Ç—Ä–∞–Ω–Ω–æ, –Ω–æ —Å–Ω–µ–≥ –≤—Å—ë –∂–µ –∫–∞–ø–∞–µ—Ç.\n",
            "–ù–∞ —É–ª–∏—Ü–µ –º–µ—Ç—ë—Ç –º–µ—Ç–µ–ª—å,\n",
            "–ì—Ä—É—Å—Ç–∏—Ç –≤—å—é–≥–∞ –Ω–∞–¥ –≥–æ–ª–æ–≤–æ–π.\n",
            "–í–¥—Ä—É–≥ –∫—Ç–æ-—Ç–æ –∏–∑ –ø—Ä–æ—Ö–æ–∂–∏—Ö –æ–∫–ª–∏–∫–∞–µ—Ç:\n",
            "‚Äî –≠–π, –≤—ã –≥–¥–µ?\n",
            "–û—Ç–≤–µ—Ç–∞ –Ω–µ—Ç.\n",
            "–ö—Ç–æ –±—ã –º–æ–≥ –ø–æ–¥—É–º–∞—Ç—å,\n",
            "–ß—Ç–æ –≤–æ—Ç —Ç–∞–∫ –∑–∞–ø—Ä–æ—Å—Ç–æ –º–æ–∂–µ—Ç –≤—ã–ø–∞—Å—Ç—å —Ç–∞–∫–æ–π —Å–Ω–µ–≥?!\n",
            "–î–∞ —á—Ç–æ –∂ —ç—Ç–æ —Ç–∞–∫–æ–µ?..\n",
            "–í–æ—Ç –≤–µ–¥—å –±–µ–¥–∞ –∫–∞–∫–∞—è!..\n",
            "–û—Å—Ç–∞—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ ‚Äî –∂–¥–∞—Ç—å‚Ä¶\n",
            "–ñ–¥–∞—Ç—å –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ —Å–Ω–µ–∂–Ω—ã–π –∫–æ–º –Ω–µ —Å–æ–±—å—ë—Ç —Ç–µ–±—è —Å –Ω–æ–≥.\n",
            "–î–æ–∂–¥—å –ª—å—ë—Ç –∫–∞–∫ –∏–∑ –≤–µ–¥—Ä–∞,\n",
            "–£–ª–∏—Ü—ã –∑–∞–ø—Ä—É–∂–µ–Ω—ã —Å–ø–µ—à–∞—â–∏–º–∏ –ø—Ä–æ—Ö–æ–∂–∏–º–∏.\n",
            "–û–Ω–∏ —Ç–æ—Ä–æ–ø—è—Ç—Å—è –∫—É–¥–∞-—Ç–æ,\n",
            "–ß—Ç–æ–± —Ö–æ—Ç—å –Ω–µ–º–Ω–æ–≥–æ —Å–æ–≥—Ä–µ—Ç—å—Å—è.\n",
            "–í–æ–¥–∞ —Å—Ç–µ–∫–∞–µ—Ç —Å–æ —â—ë–∫,\n",
            "–•–æ–ª–æ–¥ —Å–∫–æ–≤—ã–≤–∞–µ—Ç —Ä—É–∫–∏.\n",
            "–ó–∞–∂–º—É—Ä–∏–≤—à–∏—Å—å –æ—Ç —è—Ä–∫–æ–≥–æ —Å–æ–ª–Ω—Ü–∞, –æ–Ω–∏ –±—Ä–µ–¥—É—Ç –ø–æ —Ç—ë–º–Ω–æ–º—É –ø–µ—Ä–µ—É–ª–∫—É.\n",
            "–ü–æ–¥ –Ω–æ–≥–∞–º–∏ —Å–∫—Ä–∏–ø—è—Ç –ø–æ–ª–æ–≤–∏—Ü—ã,\n",
            "–ü–æ –ª—É–∂–∞–º —Å–∫–∞–ø–ª–∏–≤–∞–µ—Ç—Å—è –≥—Ä—è–∑—å.\n",
            "–®–∞–≥–∏ –∏—Ö –≥—É–ª–∫–æ –æ—Ç–¥–∞—é—Ç—Å—è –ø–æ–¥ –Ω–∞–ø–æ—Ä–æ–º –ª–µ–¥—è–Ω–æ–≥–æ –≤–µ—Ç—Ä–∞.\n",
            "–í–µ—Ç–µ—Ä —Ö–ª–µ—â–µ—Ç –∏–∑–æ –≤—Å–µ—Ö —Å–∏–ª,\n",
            "–°–ª–æ–≤–Ω–æ –∑–∞–≥–∏–ø–Ω–æ—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í–∞—É"
      ],
      "metadata": {
        "id": "ugjjL-GwX6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—É—Å—Ç—å –±—É–¥–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏ –≤—ã–±–æ—Ä –≤–µ—Ä–æ—è—Ç–Ω–æ–≥–æ"
      ],
      "metadata": {
        "id": "L1gwYGXVYY71"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhMiVGXhEGhW",
        "outputId": "4150b535-e9e6-4d97-db4b-3d897742efbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "–ü—Ä–∏—Ö–æ–¥–∏—Ç –∫–∞–∫-—Ç–æ –ú–∏–∫–µ–ª–∞–Ω–¥–∂–µ–ª–æ –≤ –°–∏–∫—Å—Ç–∏–Ω—Å–∫—É—é –∫–∞–ø–µ–ª–ª—É.  –ò –≤–∏–¥–∏—Ç –æ–Ω, —á—Ç–æ –∫ –Ω–µ–º—É –ø–æ–¥—Ö–æ–¥–∏—Ç –∫–∞–∫–æ–π-—Ç–æ —á–µ–ª–æ–≤–µ–∫ –∏ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: \n",
            " - –ß—Ç–æ —Ç—ã –∑–¥–µ—Å—å –¥–µ–ª–∞–µ—à—å? \n",
            " - –Ø –∏—â—É —á–µ–ª–æ–≤–µ–∫–∞ –ø–æ –∏–º–µ–Ω–∏ –ú–∏–∫–µ–ª–∞–Ω–¥–∂–µ–ª–æ. \n",
            " - –ê –≥–¥–µ –∂–µ –æ–Ω? \n",
            " - –û–Ω —É —Å–µ–±—è –≤ –º–∞—Å—Ç–µ—Ä—Å–∫–æ–π. \n",
            " - –ì–¥–µ –∂–µ –æ–Ω? \n",
            " - –£ —Å–µ–±—è –≤ –º–∞—Å—Ç–µ—Ä—Å–∫–æ–π. \n",
            " - –ì–¥–µ –∂–µ –æ–Ω? \n",
            " - –í –º–∞—Å—Ç–µ—Ä—Å–∫–æ–π. \n",
            " - –ì–¥–µ –∂–µ –æ–Ω? \n",
            " - –ù–∞ —á–µ—Ä–¥–∞–∫–µ. \n",
            " - –ö–∞–∫ —ç—Ç–æ –Ω–∞ —á–µ—Ä–¥–∞–∫–µ? \n",
            " - –î–∞ —Ç–∞–∫, –Ω–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ. \n",
            " - –ü–æ—á–µ–º—É –∂–µ —Ç—ã –Ω–µ —Å–∫–∞–∑–∞–ª –º–Ω–µ –æ–± —ç—Ç–æ–º —Ä–∞–Ω—å—à–µ? \n",
            " - –ù–µ –∑–Ω–∞—é. \n",
            " - –ù–æ –≤–µ–¥—å —è —Ç–µ–±–µ —Å–∫–∞–∂—É! \n",
            " - –ù–µ—Ç, –Ω–µ —Å–∫–∞–∂—É. \n",
            " - –¢–æ–≥–¥–∞ –∑–∞—á–µ–º –∂–µ —Ç—ã –º–µ–Ω—è —Å—é–¥–∞ –ø—Ä–∏—Ç–∞—â–∏–ª? \n",
            " - –ß—Ç–æ–±—ã –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å —Ç–æ–±–æ–π –æ —á–µ–º-–Ω–∏–±—É–¥—å –≤–∞–∂–Ω–æ–º. \n",
            " - –û —á–µ–º –∂–µ? \n",
            " - –û —Ç–æ–º, —á—Ç–æ —Ç–µ–±—è –º—É—á–∞–µ—Ç. \n",
            " - –¢—ã —Ö–æ—á–µ—à—å —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ –∫—Ç–æ-—Ç–æ\n"
          ]
        }
      ],
      "source": [
        "text = \"–ü—Ä–∏—Ö–æ–¥–∏—Ç –∫–∞–∫-—Ç–æ –ú–∏–∫–µ–ª–∞–Ω–¥–∂–µ–ª–æ –≤ –°–∏–∫—Å—Ç–∏–Ω—Å–∫—É—é –∫–∞–ø–µ–ª–ª—É. \"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids,\n",
        "                        do_sample=True,\n",
        "                        num_beams=6, top_k=50,\n",
        "                        max_length=200,\n",
        "                        repetition_penalty=3.5\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í–æ–æ–±—â–µ-—Ç–æ, –æ–Ω —Å–∫–∞–∑–∞–ª: \"–ó–¥—Ä–∞—Å—å—Ç–µ\", –∞ –µ–º—É: \"–ü–æ—Ç–æ–ª–æ–∫ –ø–æ–∫—Ä–∞—Å—å—Ç–µ\". –õ–µ–Ω–∞ —á–∞—Å—Ç–æ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç —ç—Ç–æ—Ç –∞–Ω–µ–∫–¥–æ—Ç."
      ],
      "metadata": {
        "id": "T-HrqBA8bLGi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHSyCXf0EGhb"
      },
      "source": [
        "### no_repeat_ngram_size\n",
        "–ê —ç—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–∞–ø—Ä—è–º—É—é –≥–æ–≤–æ—Ä–∏—Ç, —á—Ç–æ –Ω–≥—Ä–∞–º–º—ã —Ç–∞–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è —Å–æ–≤—Å–µ–º"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhcGwMoYEGhb",
        "outputId": "d436aba3-d6d2-4957-ee89-8a991b647f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "–ü—Ä–∏—Ö–æ–¥–∏—Ç –∫–∞–∫-—Ç–æ –ú–∏–∫–µ–ª–∞–Ω–¥–∂–µ–ª–æ –≤ –°–∏–∫—Å—Ç–∏–Ω—Å–∫—É—é –∫–∞–ø–µ–ª–ª—É.  –û–Ω –≤–∏–¥–∏—Ç, —á—Ç–æ —Ç–∞–º –∫—Ç–æ-—Ç–æ —Å—Ç–æ–∏—Ç –∏ —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ –Ω–µ–≥–æ.  –ò –æ–Ω —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: \"–ö—Ç–æ —ç—Ç–æ?\"  –ê —Ç–æ—Ç –æ—Ç–≤–µ—á–∞–µ—Ç: \"–°–≤—è—Ç–æ–π –æ—Ç–µ—Ü\".  –¢–∞–∫ –≤–æ—Ç, —ç—Ç–æ—Ç —Å–∞–º—ã–π —Å–≤—è—Ç–æ–π –æ—Ç–µ—Ü –≥–æ–≤–æ—Ä–∏—Ç –µ–º—É: \"–Ø –≤–∏–∂—É, —á—Ç–æ —Ç—ã —Å—Ç–æ–∏—à—å –∏ —Å–º–æ—Ç—Ä–∏—à—å –Ω–∞ –º–µ–Ω—è.  –¢—ã –≤–µ–¥—å –∑–Ω–∞–µ—à—å, —á—Ç–æ —è –∑–¥–µ—Å—å?  –Ø –∑–Ω–∞—é, —á—Ç–æ —É –º–µ–Ω—è –µ—Å—Ç—å –¥–ª—è —Ç–µ–±—è –∫–æ–µ-—á—Ç–æ...  –ù–æ –Ω–µ –≥–æ–≤–æ—Ä–∏ –º–Ω–µ –±–æ–ª—å—à–µ –æ–± —ç—Ç–æ–º!  –ù–µ –Ω–∞–∑—ã–≤–∞–π –º–µ–Ω—è —Å–≤—è—Ç—ã–º –æ—Ç—Ü–æ–º!\" \n",
            "\n",
            " –ß—Ç–æ –±—ã –≤—ã —Ö–æ—Ç–µ–ª–∏ –ø–æ–∂–µ–ª–∞—Ç—å —Å–≤–æ–∏–º –∫–ª–∏–µ–Ω—Ç–∞–º? \n",
            " –ß—Ç–æ–±—ã –≤–∞—à –±–∏–∑–Ω–µ—Å –ø—Ä–æ—Ü–≤–µ—Ç–∞–ª, \n",
            " –ß—Ç–æ–±—ã –≤–∞—à–∞ –ø—Ä–∏–±—ã–ª—å —Ä–æ—Å–ª–∞, \n",
            " –ß—Ç–æ–± –≤–∞—à–∏ –¥–æ—Ö–æ–¥—ã —Ä–æ—Å–ª–∏, \n",
            " –í–µ–¥—å —Å –∫–∞–∂–¥—ã–º –≥–æ–¥–æ–º –º—ã —Å—Ç–∞–Ω–æ–≤–∏–º—Å—è –≤—Å–µ –±–æ–≥–∞—á–µ! \n",
            " –ü—É—Å—Ç—å —Å–±—É–¥—É—Ç—Å—è –º–µ—á—Ç—ã –≤–∞—à–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤, \n",
            " –ü—É—Å—Ç—å —Å–±—ã–ª–∏—Å—å –∏—Ö –∑–∞–≤–µ—Ç–Ω—ã–µ –º–µ—á—Ç—ã! \n",
            " –ñ–µ–ª–∞–µ–º –≤–∞–º –∫—Ä–µ–ø–∫–æ–≥–æ –∑–¥–æ—Ä–æ–≤—å—è, \n",
            " –£—Å–ø–µ—Ö–æ–≤ –≤–æ –≤—Å–µ—Ö –Ω–∞—á–∏–Ω–∞–Ω–∏—è—Ö, \n",
            " –î–æ–ª–≥–∏—Ö –ª–µ—Ç –∂–∏–∑–Ω–∏, —Å—á–∞—Å—Ç—å—è –∏ –ª—é–±–≤–∏! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"–ü—Ä–∏—Ö–æ–¥–∏—Ç –∫–∞–∫-—Ç–æ –ú–∏–∫–µ–ª–∞–Ω–¥–∂–µ–ª–æ –≤ –°–∏–∫—Å—Ç–∏–Ω—Å–∫—É—é –∫–∞–ø–µ–ª–ª—É. \"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids,\n",
        "                        do_sample=True,\n",
        "                        num_beams=5, top_k=100,\n",
        "                        max_length=200,\n",
        "                        repetition_penalty=3.5,\n",
        "                        no_repeat_ngram_size=3,\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù—É –∏ –∫ —á–µ–º—É —Ç–∞–∫–∞—è –∫–æ–Ω—Ü–æ–≤–∫–∞?.. –í–æ–æ–±—â–µ, —Ç–µ–∫—Å—Ç—ã —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º —ç—Ç–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ —á–∞—Å—Ç–æ –ø–µ—Ä–µ–∫–ª—é—á–∞–ª–∏—Å—å –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –Ω–∞ –¥—Ä—É–≥—É—é —Ç–µ–º—É."
      ],
      "metadata": {
        "id": "Lftmp2CJcdXG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qBfZNUx_V0Dk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064bc272-58f2-47f0-bdcd-9bd7e252a3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "–ö–∞–∫ –≤–∞–∂–Ω–æ –±—ã—Ç—å —Å–µ—Ä—å—ë–∑–Ω—ã–º, \n",
            "–ß—Ç–æ–±—ã –Ω–µ –ø—Ä–æ—Å–ª—ã—Ç—å –¥—É—Ä–∞–∫–æ–º.\n",
            "–î–∞–≤–∞–π –ª—É—á—à–µ –æ —á—ë–º-–Ω–∏–±—É–¥—å –¥—Ä—É–≥–æ–º –ø–æ–≥–æ–≤–æ—Ä–∏–º!\n",
            "–û —Ç–æ–º, –∫–∞–∫ —è –ø—Ä–æ–≤—ë–ª –ª–µ—Ç–æ...\n",
            "–ê –ø–æ–º–Ω–∏—à—å, –º—ã —Å —Ç–æ–±–æ–π –≥—É–ª—è–ª–∏ –ø–æ –ª–µ—Å—É?\n",
            "–Ø –ø–æ–º–Ω—é, –∫–∞–∫ —Ç—ã –ø–µ–ª –º–Ω–µ –ø–µ—Å–µ–Ω–∫—É &laquo;–í –ª–µ—Å—É —Ä–æ–¥–∏–ª–∞—Å—å —ë–ª–æ—á–∫–∞&hellip;&raquo;.\n",
            "–ü–æ–º–Ω—é, –∫–∞–∫ –Ω–∞ –ø–æ–ª—è–Ω–µ —Å—Ç–æ—è–ª–∞ —ë–ª–∫–∞,\n",
            "–ò –±—ã–ª–æ —Ç–∏—Ö–æ –∏ —Å–ø–æ–∫–æ–π–Ω–æ.\n",
            "–ù–æ –≤–æ—Ç –≤ –æ–¥–∏–Ω –ø—Ä–µ–∫—Ä–∞—Å–Ω—ã–π –¥–µ–Ω—å –∫—Ç–æ-—Ç–æ –ø–æ—Å—Ç—É—á–∞–ª –≤ –µ—ë –æ–∫–Ω–æ.\n",
            "–Å–ª–æ—á–∫–∞ –≤—ã–≥–ª—è–Ω—É–ª–∞ –∏–∑ –æ–∫–æ—à–∫–∞ –∏ —É–≤–∏–¥–µ–ª–∞ –ø–µ—Ä–µ–¥ —Å–æ–±–æ–π —á–µ–ª–æ–≤–µ–∫–∞.\n",
            "–û–Ω –±—ã–ª –æ–¥–µ—Ç –≤ –∑–µ–ª—ë–Ω—ã–π –∫–æ—Å—Ç—é–º, –±–µ–ª—É—é —Ä—É–±–∞—à–∫—É –∏ —à—ë–ª–∫–æ–≤—É—é —à–ª—è–ø—É. –û–Ω –ø–æ–¥–æ—à—ë–ª –∫ –æ–∫–Ω—É –∏ —Å–ø—Ä–æ—Å–∏–ª:\n",
            "- –ö—Ç–æ —ç—Ç–æ?\n",
            "- –≠—Ç–æ —è, - –æ—Ç–≤–µ—Ç–∏–ª–∞ –Å–ª–æ—á–∫–∞.\n",
            "- –ê –æ—Ç–∫—É–¥–∞ –≤—ã –∑–Ω–∞–µ—Ç–µ –º–æ—ë –∏–º—è?\n",
            "–ï–ª–æ—á–∫–∞ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∞ –Ω–∞ –Ω–µ–≥–æ —à–∏—Ä–æ–∫–æ —Ä–∞—Å–∫—Ä—ã—Ç—ã–º–∏ –≥–ª–∞–∑–∞–º–∏ –∏ —Å–º—É—â—ë–Ω–Ω–æ –ø–æ—Ç—É–ø–∏–ª–∞ –≥–ª–∞–∑–∞.\n",
            "–ß–µ–ª–æ–≤–µ–∫ —É–ª—ã–±–Ω—É–ª—Å—è –µ–π –∏ —Å–∫–∞–∑–∞–ª:\n"
          ]
        }
      ],
      "source": [
        "text = \"–ö–∞–∫ –≤–∞–∂–Ω–æ –±—ã—Ç—å —Å–µ—Ä—å—ë–∑–Ω—ã–º, \"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids,\n",
        "                        do_sample=True,\n",
        "                        num_beams=5, top_k=100,\n",
        "                        max_length=200,\n",
        "                        repetition_penalty=3.5,\n",
        "                        no_repeat_ngram_size=3,\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"–ü–æ–±—ã–≤–∞—Ç—å –≤ —Å–∫–∞–∑–æ—á–Ω–æ–º –º–µ—Å—Ç–µ \"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "for temp in [0.001, 0.1, 0.2, 0.5, 0.7, 1., 5.]:\n",
        "\n",
        "    out = model.generate(input_ids, do_sample=True,\n",
        "                     top_k=0,\n",
        "                     temperature=temp,\n",
        "                     max_length=50,\n",
        "                     repetition_penalty=2.)\n",
        "\n",
        "\n",
        "    generated_text = list(map(tokenizer.decode, out))[0]\n",
        "    print(\"### text with temp - \", temp)\n",
        "    print(generated_text)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUGy3TD4eSKF",
        "outputId": "bde22ebe-59ce-4444-d101-84cb551d2ce8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### text with temp -  0.001\n",
            "–ü–æ–±—ã–≤–∞—Ç—å –≤ —Å–∫–∞–∑–æ—á–Ω–æ–º –º–µ—Å—Ç–µ \n",
            "–ò —É–≤–∏–¥–µ—Ç—å –≤–æ–ª—à–µ–±–Ω—ã–π –º–∏—Ä, \n",
            "        –ò —É—Å–ª—ã—à–∞—Ç—å –≥–æ–ª–æ—Å –≤–æ–ª—à–µ–±–Ω–æ–π –ø—Ç–∏—Ü—ã.   \\t\\thttp://www1doma-magazin/posts_138775#\n",
            "\n",
            "### text with temp -  0.1\n",
            "–ü–æ–±—ã–≤–∞—Ç—å –≤ —Å–∫–∞–∑–æ—á–Ω–æ–º –º–µ—Å—Ç–µ \n",
            "–ò —É–≤–∏–¥–µ—Ç—å –≤–æ–ª—à–µ–±–Ω—ã–π –º–∏—Ä, \n",
            "        –ò —É—Å–ª—ã—à–∞—Ç—å –≥–æ–ª–æ—Å –≤–æ–ª—à–µ–±–Ω–æ–π –ø—Ç–∏—Ü—ã.   \\t\\thttp://www1domainstudio/files-2129465_pok\n",
            "\n",
            "### text with temp -  0.2\n",
            "–ü–æ–±—ã–≤–∞—Ç—å –≤ —Å–∫–∞–∑–æ—á–Ω–æ–º –º–µ—Å—Ç–µ \n",
            "–ò —É–≤–∏–¥–µ—Ç—å –≤–æ–ª—à–µ–±–Ω–æ–µ —á—É–¥–æ, \n",
            "        –ò —É—Å–ª—ã—à–∞—Ç—å –≥–æ–ª–æ—Å –≤–æ–ª—à–µ–±–Ω–æ–π –ø—Ç–∏—Ü—ã.   \\t\\thttp://www1domainstudio/posts-2123456789\n",
            "\n",
            "### text with temp -  0.5\n",
            "–ü–æ–±—ã–≤–∞—Ç—å –≤ —Å–∫–∞–∑–æ—á–Ω–æ–º –º–µ—Å—Ç–µ \n",
            "–í —á—É–¥–µ—Å–Ω–æ–º, –≤–æ–ª—à–µ–±—Å—Ç–≤–µ. –ù–µ –∑—Ä—è –≥–æ–≤–æ—Ä—è—Ç: ¬´–ó–¥–µ—Å—å –≤—Å–µ —á—É–¥–∏—Ç—Å—è¬ª. –ù–æ –º—ã –Ω–µ –∑–Ω–∞–µ–º —Ç–æ—á–Ω–æ ‚Äì –≥–¥–µ –æ–Ω–æ? –ò —á—Ç–æ —ç—Ç–æ –∑–∞ –º–µ—Å—Ç–æ —Ç–∞–∫–æ–µ‚Ä¶ –ö–∞–∫ –ø–æ—ë—Ç—Å—è —É –ê–Ω–¥–µ—Ä—Å–µ–Ω–∞ –ø–æ–¥ –æ–∫–Ω–æ–º\n",
            "\n",
            "### text with temp -  0.7\n",
            "–ü–æ–±—ã–≤–∞—Ç—å –≤ —Å–∫–∞–∑–æ—á–Ω–æ–º –º–µ—Å—Ç–µ \n",
            "–ë–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤, –±–µ–∑ —Å—É–µ—Ç—ã. –ò –æ—Å—Ç–∞—Ç—å—Å—è —Å —Ç–æ–±–æ—é –Ω–∞–≤—Å–µ–≥–¥–∞! \n",
            "   –û —á—ë–º –≥–æ–≤–æ—Ä–∏—Ç—å? –ß—Ç–æ –¥–µ–ª–∞—Ç—å –∏ –≥–¥–µ –∏—Å–∫–∞—Ç—å –æ—Ç–≤–µ—Ç—ã‚Ä¶ –ê —á—Ç–æ –±—ã —Ç—ã —Ö–æ—Ç–µ–ª —É–∑–Ω–∞—Ç—å –æ –º–∏—Ä–µ –∂–∏–≤—ã—Ö?.. –†–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ –≤—Å—ë —Å–≤–æ—ë –¥–µ—Ç—Å—Ç–≤–æ\n",
            "\n",
            "### text with temp -  1.0\n",
            "–ü–æ–±—ã–≤–∞—Ç—å –≤ —Å–∫–∞–∑–æ—á–Ω–æ–º –º–µ—Å—Ç–µ ^\n",
            "–ñ–∏–ª–∞-–±—ã–ª–∞ –¥–µ–≤–æ—á–∫–∞, –∫–æ—Ç–æ—Ä–æ–π –Ω–∞ –≥–æ—Ä–æ—à–∏–Ω–µ —Ä–∏—Å–æ–≤–∞–ª–∏ —Ç–æ—á–∫—É. –õ–µ—Ç–µ–ª–∞ - –∏ –≤—ã—Ä–æ—Å–ª–∞! –û—Ç—É—á–∏–ª–∞—Å—å —Ö–æ—Ä–æ—à–æ: –ü–µ–ª–∏ –ø—Ç–∏—Ü—ã –ø—Ç–∏—á–∫–∏ —Ä–∞–∑–Ω—ã–µ –ø–µ—Å–Ω–∏ –ø—Ä–æ —Å–µ–±—è –¥–∞ –ü–æ–ø–∫–æ–≤ —Å–æ–Ω–Ω—ã—Ö —Å\n",
            "\n",
            "### text with temp -  5.0\n",
            "–ü–æ–±—ã–≤–∞—Ç—å –≤ —Å–∫–∞–∑–æ—á–Ω–æ–º –º–µ—Å—Ç–µ  –ø—Ä–æ—è–≤–∏—Ç—å –ø–∞–ª—å—Ü–µ–≤ –ì—Ä–æ–¥ —è–π—Ü–∞ —Å–æ–±–∏—Ä–∞–ª–∏ –°–∫–∞ –≤–ª–∞–¥–µ–ª—å—Ü—ã –≤–∑ –ø–µ—Ä–µ–º–∏—Ä–∏—è —Ä–µ–ø—Ä–µ—Å—Å–∏ –≤–µ—Ç—Ä–æ–º Russia –º–∏–º–æ–ª–µ—Ç—Å—Ç—ã–π –∏–Ω—Ç–µ–Ω—Å–∏–≤ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å—Ç—Ä–æ–∏—Ç–≤–∏–∞ –∑–∞–¥—É–º–∞—Ç—å—Å—è –≥–∏–º–Ω—Ü–µ–≤ –æ–±–æ–∏–º –∑–Ω–∞–µ—à—å–∞–Ω –ø—Ä–∏–±–∞ –ñ–µ–Ω—â–∏–Ω–∞ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–π –ø–æ–∑–∞–±–æ–æ—Ç–∏–≤–µ–Ω–Ω–æ Bu–Ω–µ–π—à–µ–µ –∫–∞–ø–ª—è–ø—Å–∏—Ö –°—Ç—Ä–∞–Ω —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞ languages —Å–≤—ã—à–µ –ö–∞—Ä—Ç–∞ –æ–±—ã—á–Ω—ã–º–æ–ª–∞–≥–∞—é –æ–≥—Ä–æ–º–Ω–æ–º\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í –æ–±—â–µ–º, –º–Ω–µ 0.5-0.7 –Ω—Ä–∞–≤–∏—Ç—Å—è"
      ],
      "metadata": {
        "id": "Jr2WkDhogJVJ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}