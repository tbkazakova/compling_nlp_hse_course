{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0592859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from razdel import tokenize\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60452fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tbkazakova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a21d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ru = stopwords.words('russian')\n",
    "stopwords_ru.append('тебе')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbffbbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2477b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)\n",
    "# токсичных в 2 раза меньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a07af34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3150c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# векторизовали с дефолтной токенизацией\n",
    "vect_tfidf_default = TfidfVectorizer(min_df=10, max_df=0.3)\n",
    "X_deftok = vect_tfidf_default.fit_transform(train.comment)\n",
    "X_deftok_test = vect_tfidf_default.transform(test.comment)\n",
    "y_deftok = train.toxic.values\n",
    "y_deftok_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1076873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С дефолтной векторизацией\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.84      0.87       963\n",
      "         1.0       0.72      0.79      0.75       479\n",
      "\n",
      "    accuracy                           0.83      1442\n",
      "   macro avg       0.80      0.82      0.81      1442\n",
      "weighted avg       0.83      0.83      0.83      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf.fit(X_deftok, y_deftok)\n",
    "preds = clf.predict(X_deftok_test)\n",
    "print(\"С дефолтной векторизацией\")\n",
    "print(classification_report(y_deftok_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70dc5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наша токенизация\n",
    "train_razdel_toks = []\n",
    "for i, row in train.iterrows():\n",
    "    tokens = [_.text for _ in list(tokenize(row['comment']))]\n",
    "    train_razdel_toks.append(tokens)\n",
    "test_razdel_toks = []\n",
    "for i, row in test.iterrows():\n",
    "    tokens = [_.text for _ in list(tokenize(row['comment']))]\n",
    "    test_razdel_toks.append(tokens)\n",
    "\n",
    "# Можно было то, что сверху, положить в identity_tokenizer, но я этого не сделала.\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b8d9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tfidf_razdel = TfidfVectorizer(tokenizer=identity_tokenizer,\n",
    "                                    lowercase=False,\n",
    "                                    min_df=10,\n",
    "                                    max_df=0.3)\n",
    "X_razdtok = vect_tfidf_razdel.fit_transform(train_razdel_toks)\n",
    "X_razdtok_test = vect_tfidf_razdel.transform(test_razdel_toks)\n",
    "y_razdtok = train.toxic.values\n",
    "y_razdtok_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8693a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С векторизацией razdel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.82      0.85       963\n",
      "         1.0       0.68      0.77      0.72       479\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.78      0.79      0.78      1442\n",
      "weighted avg       0.81      0.80      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf.fit(X_razdtok, y_razdtok)\n",
    "preds = clf.predict(X_razdtok_test)\n",
    "print(\"С векторизацией razdel\")\n",
    "print(classification_report(y_razdtok_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c7f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Я думала, что результаты с razdel чуть лучше будут.\n",
    "# Несколько раз перезапустила. Иногда дефолтная, а иногда токенизация razdel выигрывает.\n",
    "# Значит, разница несущественная."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c896c",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd27a3",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b50abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>я и ты</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ты и я</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>я, я и только я</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>только не я</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>он</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text         я        ты         и    только        не   он\n",
       "0           я и ты  0.333333  0.333333  0.333333  0.000000  0.000000  0.0\n",
       "1           ты и я  0.333333  0.333333  0.333333  0.000000  0.000000  0.0\n",
       "2  я, я и только я  0.600000  0.000000  0.200000  0.200000  0.000000  0.0\n",
       "3      только не я  0.333333  0.000000  0.000000  0.333333  0.333333  0.0\n",
       "4               он  0.000000  0.000000  0.000000  0.000000  0.000000  1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onethird = 1/3\n",
    "table = {\n",
    "    'text':[\"я и ты\", \"ты и я\", \"я, я и только я\", \"только не я\", \"он\"],\n",
    "    'я':[onethird, onethird, 0.6, onethird, 0],\n",
    "    'ты':[onethird, onethird, 0, 0, 0],\n",
    "    'и':[onethird, onethird, 0.2, 0, 0],\n",
    "    'только':[0, 0, 0.2, onethird, 0],\n",
    "    'не':[0, 0, 0, onethird, 0],\n",
    "    'он':[0, 0, 0, 0, 1.0]}\n",
    "table = pd.DataFrame(table)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8206faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['я', 'ты', 'и', 'только', 'не', 'он']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "206cfae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>я и ты</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.170275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ты и я</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.170275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>я, я и только я</td>\n",
       "      <td>0.133886</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.102165</td>\n",
       "      <td>0.183258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>только не я</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305430</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>он</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              text         я       ты         и    только        не        он\n",
       "0           я и ты  0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
       "1           ты и я  0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
       "2  я, я и только я  0.133886  0.00000  0.102165  0.183258  0.000000  0.000000\n",
       "3      только не я  0.074381  0.00000  0.000000  0.305430  0.536479  0.000000\n",
       "4               он  0.000000  0.00000  0.000000  0.000000  0.000000  1.609438"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_tfidf = pd.DataFrame(columns=['text', 'я', 'ты', 'и', 'только', 'не', 'он'])\n",
    "\n",
    "for s, row in table.iterrows():\n",
    "    word_tfidf = [row['text']]\n",
    "    for w in range(len(words)):\n",
    "        tf = row[words[w]]\n",
    "        df = 0\n",
    "        for word_freq in list(table[words[w]]):\n",
    "            if word_freq > 0:\n",
    "                df += 1\n",
    "        if tf == 0:\n",
    "            tfidf = 0\n",
    "        else:\n",
    "            tfidf = tf * math.log(len(table)/df)\n",
    "        word_tfidf.append(tfidf)\n",
    "    table_tfidf.loc[len(table_tfidf.index)] = word_tfidf\n",
    "table_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec6c3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# смотрим униграммы и биграммы с токенизацией от razdel\n",
    "vect_tfidf_razdel = TfidfVectorizer(tokenizer=identity_tokenizer,\n",
    "                                    lowercase=False,\n",
    "                                    ngram_range=(1,2),\n",
    "                                    min_df=5,\n",
    "                                    max_df=0.3)\n",
    "X_razdtok = vect_tfidf_razdel.fit_transform(train_razdel_toks)\n",
    "X_razdtok_test = vect_tfidf_razdel.transform(test_razdel_toks)\n",
    "y_razdtok = train.toxic.values\n",
    "y_razdtok_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9b130b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.97      0.89       963\n",
      "         1.0       0.91      0.56      0.69       479\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.87      0.77      0.79      1442\n",
      "weighted avg       0.85      0.84      0.82      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=0.9, class_prior=[0.66514, 0.33486])\n",
    "nb.fit(X_razdtok, y_razdtok)\n",
    "preds = nb.predict(X_razdtok_test)\n",
    "\n",
    "print(classification_report(y_razdtok_test, preds))\n",
    "\n",
    "# Я попробовала GaussianNB, но по метрикам получалось хуже.\n",
    "# А ещё я не понимаю, насколько логично использовать MultinomialNB, если у нас 2 категории.\n",
    "# Может, для случая с 2мя категориями есть более хорошее NB решение..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8417a3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('По мексикански Флаг: Ублюдок, мать твою, а ну иди сюда говно собачье, решил меня поднять? Ты, засранец вонючий, мать твою, а? Ну иди сюда, попробуй меня поднять, я тебя сам подниму ублюдок, онанист чертов, будь ты проклят, иди идиот, трахать тебя и всю семью, говно собачье, жлоб вонючий, дерьмо, сука, падла, иди сюда, мерзавец, негодяй, гад, иди сюда ты - говно, ЖОПА!\\n',\n",
       "  0.996005534378624),\n",
       " ('Ты охуела, мразь? Я же тебя найду блять. Гридин не свинья, ты понял, петух? НЕ СМЕЙ НАЗЫВАТЬ КУЗЬМУ СВИНЬЕЙ ДЭБИЛ ГОРОХОВЫЙ!\\n',\n",
       "  0.9932742880330429),\n",
       " ('НУ ВОТ, ЕРОХИН УЖЕ СВАЛИЛ ЗА БУГОР, А ТЫ ВС СИДИШЬ КАК СЫЧ В СВОЕМ ПО И СИСЯНУ ДОНАТИШЬ!!\\n',\n",
       "  0.9916468522994305),\n",
       " ('кукарекнула то, о чем на харкаче последний сосницкий уже докторскую защитил и тысячи тредов высрал ЕБАТЬ ФУРОР НАХУЙ. ВОТ ЭТА ДА? ДА КАК МЫ СРАЗУ НЕ ДАГАДАЛИСЬ ТО ЕБАТЬ. АЙДА НА ПЕРЕДАЧУ РАССКАЖЕШЬ ЧЕ ТАМ ДА КАК Больные пиндосы. Еврокуколды рили создают впечатление какого то умственно отсталого народа имбецила.\\n',\n",
       "  0.990921281008845),\n",
       " ('Блядь абу нахуй ссылай этих дегенератов в фаг, всем похуй на их шлюх\\n',\n",
       "  0.977323177960113),\n",
       " ('ЕСЛИ БЫ ОДНОКЛАССНИКИ НЕ РАЗБИЛИ ПЯТИКЛАШКЕ ЕБАЛО, ТО ЕГО РАЗБИЛИ БЫ СОЛДАТЫ НАТО!!!!\\n',\n",
       "  0.9771200395289907),\n",
       " ('Эдвард Билл вас в жопу бил? Ыыыыы мазафакка сука\\n', 0.9719467109758362),\n",
       " ('Бесплатный долбоеб, ты? Выйди нахуй из треда\\n', 0.9700635828878709),\n",
       " ('БРОСАЙ БЛЯТЬ Бросил. Пистолет выстрелил. Убил тётку. Полицейский обосрался и убил тебя.\\n',\n",
       "  0.9674194826907065),\n",
       " ('Бля ты заебал уже. Ты покажи конкретно где шитпост, я вообще не ебу что у тебя в голове.\\n',\n",
       "  0.9673181844473944)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = nb.predict_proba(X_razdtok_test)\n",
    "nb_probs = Counter()\n",
    "for i in range(len(test.comment)):\n",
    "    nb_probs[test.comment[i]] = float(probas[i][1])\n",
    "nb_probs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "839a5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_CountVect = CountVectorizer(ngram_range=(1, 3),\n",
    "                                 min_df=5,\n",
    "                                 max_df=0.2,\n",
    "                                 stop_words=stopwords_ru,\n",
    "                                 analyzer='char_wb')\n",
    "X = vect_CountVect.fit_transform(train.comment)\n",
    "X_test = vect_CountVect.transform(test.comment)\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06659236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.95      0.87       963\n",
      "         1.0       0.85      0.53      0.65       479\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.82      0.74      0.76      1442\n",
      "weighted avg       0.82      0.81      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nclf = KNeighborsClassifier(n_neighbors=8, metric='cosine')\n",
    "nclf.fit(X, y)\n",
    "preds = nclf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cabf05c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Лахтодебил, ты читать умеешь? Я же говорю жрёт дохуя, а не едет нихуя.\\n',\n",
       "  1.0),\n",
       " ('Ох, свежайший приём сам дурак , ты из детского сада пишешь, что ли? Воистину, нацея дигродирует.\\n',\n",
       "  1.0),\n",
       " ('Нахуй тебе видосы с резиновой куклой, фетишист штоле?\\n', 1.0),\n",
       " ('ты долбоеб чтоле, под кроватью куколдов ищи\\n', 1.0),\n",
       " ('КОНЧ, долбаёб. Их словечко. Соси хуй, я ебал твою мать.\\n', 1.0),\n",
       " ('Павел Михайловский казалось бы, причём здесь хохлы\\n', 1.0),\n",
       " ('ЕБАНЫЕ ПИДОРЫ, КОГДА ПОРТИРУЕТЕ ТЕНИ КОЛОССОВ?\\n', 1.0),\n",
       " ('Пиздешь Опять с продленки съебался?\\n', 1.0),\n",
       " ('Тиньков был пиздец как прав, что блогеры продажные. Долго до тебя доходило.\\n',\n",
       "  1.0),\n",
       " ('Похуй не может быть мучительно. Похуй всегда похуй\\n', 1.0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = nclf.predict_proba(X_test)\n",
    "nclf_probs = Counter()\n",
    "for i in range(len(test.comment)):\n",
    "    nclf_probs[test.comment[i]] = float(probas[i][1])\n",
    "nclf_probs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91573862",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По мексикански Флаг: Ублюдок, мать твою, а ну иди сюда говно собачье, решил меня поднять? Ты, засранец вонючий, мать твою, а? Ну иди сюда, попробуй меня поднять, я тебя сам подниму ублюдок, онанист чертов, будь ты проклят, иди идиот, трахать тебя и всю семью, говно собачье, жлоб вонючий, дерьмо, сука, падла, иди сюда, мерзавец, негодяй, гад, иди сюда ты - говно, ЖОПА!\n",
      "\n",
      "Ты охуела, мразь? Я же тебя найду блять. Гридин не свинья, ты понял, петух? НЕ СМЕЙ НАЗЫВАТЬ КУЗЬМУ СВИНЬЕЙ ДЭБИЛ ГОРОХОВЫЙ!\n",
      "\n",
      "НУ ВОТ, ЕРОХИН УЖЕ СВАЛИЛ ЗА БУГОР, А ТЫ ВС СИДИШЬ КАК СЫЧ В СВОЕМ ПО И СИСЯНУ ДОНАТИШЬ!!\n",
      "\n",
      "кукарекнула то, о чем на харкаче последний сосницкий уже докторскую защитил и тысячи тредов высрал ЕБАТЬ ФУРОР НАХУЙ. ВОТ ЭТА ДА? ДА КАК МЫ СРАЗУ НЕ ДАГАДАЛИСЬ ТО ЕБАТЬ. АЙДА НА ПЕРЕДАЧУ РАССКАЖЕШЬ ЧЕ ТАМ ДА КАК Больные пиндосы. Еврокуколды рили создают впечатление какого то умственно отсталого народа имбецила.\n",
      "\n",
      "ЕСЛИ БЫ ОДНОКЛАССНИКИ НЕ РАЗБИЛИ ПЯТИКЛАШКЕ ЕБАЛО, ТО ЕГО РАЗБИЛИ БЫ СОЛДАТЫ НАТО!!!!\n",
      "\n",
      "Бесплатный долбоеб, ты? Выйди нахуй из треда\n",
      "\n",
      "БРОСАЙ БЛЯТЬ Бросил. Пистолет выстрелил. Убил тётку. Полицейский обосрался и убил тебя.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Итог:\n",
    "# KNeighborsClassifier для первых 50 с чем-то реплик уверенно предлагает абсолютную токсичность. (1.0)\n",
    "# Среди них есть все из 10ти от NB?\n",
    "nb_10 = []\n",
    "for text in nb_probs.most_common(10):\n",
    "    nb_10.append(text[0])\n",
    "nclf_56 = []\n",
    "for text in nclf_probs.most_common(56):\n",
    "    nclf_56.append(text[0])\n",
    "for text in nb_10:\n",
    "    if text not in nclf_56:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bf2e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среди 50 с чем-то самых токсичных реплик по мнению KNeighborsClassifier нет некоторых\n",
    "# из топ-10 от MultinomialNB.\n",
    "# ('Павел Михайловский казалось бы, причём здесь хохлы\\n', 1.0) - менее токсичное, чем что-нибудь из списка выше\n",
    "# MultinomialNB точнее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression и Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d610b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tfidf = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                             min_df=5,\n",
    "                             max_df=0.2,\n",
    "                             stop_words=stopwords_ru)\n",
    "# хотя tfidf убирает многие стопслова сам\n",
    "\n",
    "X = vect_tfidf.fit_transform(train.comment)\n",
    "X_test = vect_tfidf.transform(test.comment)\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df90d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7975"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# словарь, индексы в списке соответствуют колонкам в матрице\n",
    "wordlist = [x for x in vect_tfidf.get_feature_names()]\n",
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81f86878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.85      0.87       963\n",
      "         1.0       0.73      0.81      0.77       479\n",
      "\n",
      "    accuracy                           0.83      1442\n",
      "   macro avg       0.81      0.83      0.82      1442\n",
      "weighted avg       0.84      0.83      0.84      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7de86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = clf.coef_\n",
    "clf_features = Counter()\n",
    "for i in range(len(wordlist)):\n",
    "    clf_features[wordlist[i]] = importance[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81203391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('хохлы', 1.6188025163209192),\n",
       " ('хохлов', 1.5304765660977848),\n",
       " ('нахуй', 1.2591559014154463),\n",
       " ('блять', 1.097152757505994),\n",
       " ('блядь', 1.0728852581931798)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_features.most_common(5) #.. # надо было лемматизировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15af4e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      1.00      0.81       963\n",
      "         1.0       1.00      0.06      0.11       479\n",
      "\n",
      "    accuracy                           0.69      1442\n",
      "   macro avg       0.84      0.53      0.46      1442\n",
      "weighted avg       0.79      0.69      0.58      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20, )\n",
    "rf.fit(X, y)\n",
    "preds = rf.predict(X_test)\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d38dd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = rf.feature_importances_\n",
    "rf_features = Counter()\n",
    "for i in range(len(wordlist)):\n",
    "    rf_features[wordlist[i]] = importance[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d53dc86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('хохлов', 0.03216869148827162),\n",
       " ('хохлы', 0.02559543133338842),\n",
       " ('нахуй', 0.022729095948384553),\n",
       " ('сука', 0.017434721787487926),\n",
       " ('очень', 0.01632676877595195)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_features.most_common(5)  # слово \"очень\" не очень подходит"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
